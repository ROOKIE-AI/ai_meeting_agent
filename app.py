"""
ä¼šè®®å‡†å¤‡AIåŠ©æ‰‹åº”ç”¨
è¿™ä¸ªæ¨¡å—å®ç°äº†ä¸€ä¸ªåŸºäºStreamlitçš„ä¼šè®®å‡†å¤‡AIåŠ©æ‰‹ï¼Œåˆ©ç”¨OpenAIçš„GPTæ¨¡å‹å’Œç»´åŸºç™¾ç§‘æœç´¢åŠŸèƒ½ï¼Œ
ç”Ÿæˆå…¨é¢çš„ä¼šè®®å‡†å¤‡ææ–™ã€‚ç³»ç»Ÿé€šè¿‡å¤šä¸ªAIåŠ©æ‰‹ååŒå·¥ä½œï¼Œæä¾›ä¼šè®®èƒŒæ™¯åˆ†æã€
è¡Œä¸šè¶‹åŠ¿åˆ†æã€ä¼šè®®ç­–ç•¥åˆ¶å®šå’Œæ‰§è¡Œç®€æŠ¥ç”Ÿæˆç­‰å¤šç§åŠŸèƒ½ã€‚

ä¸»è¦åŠŸèƒ½ï¼š
    - å¤šAIåŠ©æ‰‹ååŒå·¥ä½œç³»ç»Ÿ
    - å®æ—¶åˆ†æè¿›åº¦å±•ç¤º
    - ä¸­æ–‡ç»´åŸºç™¾ç§‘é›†æˆ
    - å¯é…ç½®çš„AIæ¨¡å‹å‚æ•°
    - æ–‡æ¡£æ™ºèƒ½å¤„ç†åˆ†æ

Author: Rookie
Date: 2025-02-20
"""

__import__('pysqlite3')  
import sys  
sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')

import streamlit as st
from crewai import Agent, Task, Crew, LLM
from crewai.process import Process
from langchain_community.tools import WikipediaQueryRun
from langchain_community.utilities import WikipediaAPIWrapper
from typing import Any, List, Dict
import os
from datetime import datetime
import docx
import pandas as pd
import PyPDF2
import io
from PIL import Image
import pytesseract
import json
import zipfile
import requests
from bs4 import BeautifulSoup

class DocumentProcessor:
    """æ–‡æ¡£å¤„ç†å™¨ç±»ï¼Œç”¨äºå¤„ç†å„ç§ç±»å‹çš„æ–‡æ¡£å¹¶æå–ä¿¡æ¯ã€‚"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ–‡æ¡£å¤„ç†å™¨"""
        self.supported_extensions = {
            'text': ['.txt', '.md'],
            'document': ['.doc', '.docx'],
            'spreadsheet': ['.xls', '.xlsx', '.csv'],
            'presentation': ['.ppt', '.pptx'],
            'pdf': ['.pdf'],
            'image': ['.jpg', '.jpeg', '.png'],
            'archive': ['.zip', '.rar']
        }
    
    def validate_file(self, file) -> bool:
        """éªŒè¯æ–‡ä»¶æ ¼å¼æ˜¯å¦æ”¯æŒ"""
        if not file:
            return False
        ext = os.path.splitext(file.name)[1].lower()
        return any(ext in exts for exts in self.supported_extensions.values())
    
    def extract_text_from_docx(self, file) -> str:
        """ä»Wordæ–‡æ¡£ä¸­æå–æ–‡æœ¬"""
        doc = docx.Document(file)
        return '\n'.join([paragraph.text for paragraph in doc.paragraphs])
    
    def extract_text_from_pdf(self, file) -> str:
        """ä»PDFæ–‡ä»¶ä¸­æå–æ–‡æœ¬"""
        pdf_reader = PyPDF2.PdfReader(file)
        return '\n'.join([page.extract_text() for page in pdf_reader.pages])
    
    def extract_text_from_image(self, file) -> str:
        """ä»å›¾ç‰‡ä¸­æå–æ–‡æœ¬"""
        image = Image.open(file)
        return pytesseract.image_to_string(image, lang='chi_sim+eng')
    
    def extract_data_from_excel(self, file) -> Dict:
        """ä»Excelæ–‡ä»¶ä¸­æå–æ•°æ®"""
        df = pd.read_excel(file)
        return {
            'headers': df.columns.tolist(),
            'data': df.values.tolist(),
            'summary': df.describe().to_dict()
        }
    
    def extract_from_url(self, url: str) -> str:
        """ä»URLä¸­æå–å†…å®¹"""
        response = requests.get(url)
        soup = BeautifulSoup(response.text, 'html.parser')
        return soup.get_text()
    
    def process_file(self, file) -> Dict:
        """å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶å¹¶æå–ä¿¡æ¯"""
        try:
            file_ext = os.path.splitext(file.name)[1].lower()
            content = ''
            
            if file_ext in self.supported_extensions['document']:
                content = self.extract_text_from_docx(file)
            elif file_ext in self.supported_extensions['pdf']:
                content = self.extract_text_from_pdf(file)
            elif file_ext in self.supported_extensions['text']:
                content = file.getvalue().decode('utf-8')
            elif file_ext in self.supported_extensions['image']:
                content = self.extract_text_from_image(file)
            elif file_ext in self.supported_extensions['spreadsheet']:
                content = json.dumps(self.extract_data_from_excel(file))
            
            return {
                'filename': file.name,
                'content': content,
                'type': file_ext,
                'size': file.size,
                'timestamp': datetime.now().isoformat()
            }
        except Exception as e:
            return {
                'filename': file.name,
                'error': str(e),
                'type': file_ext,
                'size': file.size,
                'timestamp': datetime.now().isoformat()
            }

# æ·»åŠ æ–‡æ¡£å¤„ç†å™¨åˆ°session_state
if 'doc_processor' not in st.session_state:
    st.session_state.doc_processor = DocumentProcessor()

# æ·»åŠ æ–‡æ¡£å­˜å‚¨åˆ°session_state
if 'uploaded_docs' not in st.session_state:
    st.session_state.uploaded_docs = []

# æ·»åŠ æ–‡æ¡£åˆ†æç»“æœåˆ°session_state
if 'doc_analysis' not in st.session_state:
    st.session_state.doc_analysis = {}

# æ·»åŠ å·¥å…·åŒ…è£…ç±»
class WikipediaToolWrapper:
    def __init__(self):
        self.name = "wikipedia"
        self.description = "ä½¿ç”¨ç»´åŸºç™¾ç§‘æœç´¢ä¿¡æ¯çš„å·¥å…·"
        self.wiki_tool = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(lang="zh"))
    
    def func(self, query: str) -> str:
        try:
            return self.wiki_tool.run(query)
        except Exception as e:
            return f"æœç´¢æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"

# Streamlit åº”ç”¨è®¾ç½®
st.set_page_config(page_title="ä¼šè®®å‡†å¤‡AIåŠ©æ‰‹ ğŸ“", layout="wide")
st.title("ä¼šè®®å‡†å¤‡AIåŠ©æ‰‹ ğŸ“")

# åˆ›å»ºåˆ†æè¿‡ç¨‹æ˜¾ç¤ºåŒºåŸŸ
if 'analysis_log' not in st.session_state:
    st.session_state.analysis_log = []
    
# åœ¨session_stateä¸­æ·»åŠ å¯¼èˆªçŠ¶æ€
if 'current_view' not in st.session_state:
    st.session_state.current_view = "input"
    st.session_state.has_data = False  # æ·»åŠ æ•°æ®çŠ¶æ€æ ‡å¿—

# æ·»åŠ å¯¼èˆªæ 
nav_col1, nav_col2, nav_col3, nav_col4, nav_col5 = st.columns(5)
with nav_col1:
    if st.button("ğŸ“ è¾“å…¥ä¿¡æ¯", use_container_width=True):
        st.session_state.current_view = "input"
with nav_col2:
    if st.button("ğŸ” ä¼šè®®èƒŒæ™¯", use_container_width=True):
        if st.session_state.expert_analysis['context']['result']:
            st.session_state.current_view = "context"
        else:
            st.warning("è¯·å…ˆå®Œæˆä¼šè®®å‡†å¤‡åˆ†æã€‚")
with nav_col3:
    if st.button("ğŸ“ˆ è¡Œä¸šè¶‹åŠ¿", use_container_width=True):
        if st.session_state.expert_analysis['industry']['result']:
            st.session_state.current_view = "industry"
        else:
            st.warning("è¯·å…ˆå®Œæˆä¼šè®®å‡†å¤‡åˆ†æã€‚")
with nav_col4:
    if st.button("ğŸ“‹ ä¼šè®®ç­–ç•¥", use_container_width=True):
        if st.session_state.expert_analysis['strategy']['result']:
            st.session_state.current_view = "strategy"
        else:
            st.warning("è¯·å…ˆå®Œæˆä¼šè®®å‡†å¤‡åˆ†æã€‚")
with nav_col5:
    if st.button("ğŸ“‘ æ‰§è¡Œç®€æŠ¥", use_container_width=True):
        if st.session_state.expert_analysis['briefing']['result']:
            st.session_state.current_view = "briefing"
        else:
            st.warning("è¯·å…ˆå®Œæˆä¼šè®®å‡†å¤‡åˆ†æã€‚")

st.divider()

# åœ¨session_stateä¸­æ·»åŠ ä¸“å®¶åˆ†æç»“æœå­˜å‚¨
if 'expert_analysis' not in st.session_state:
    st.session_state.expert_analysis = {
        'context': {'result': '', 'thoughts': [], 'analysis': []},
        'industry': {'result': '', 'thoughts': [], 'analysis': []},
        'strategy': {'result': '', 'thoughts': [], 'analysis': []},
        'briefing': {'result': '', 'thoughts': [], 'analysis': []}
    }

# æ·»åŠ llmåˆ°session_state
if 'llm' not in st.session_state:
    st.session_state.llm = None

# æ·»åŠ å®æ—¶æ—¥å¿—å®¹å™¨åˆ°session_state
if 'analysis_log' not in st.session_state:
    st.session_state.analysis_log = []

def add_log(message: str) -> None:
    """
    å‘åˆ†ææ—¥å¿—ä¸­æ·»åŠ æ–°çš„æ¶ˆæ¯ï¼Œå¹¶å®æ—¶æ˜¾ç¤ºåœ¨é¡µé¢ä¸Šã€‚

    Args:
        message (str): è¦æ·»åŠ åˆ°æ—¥å¿—çš„æ¶ˆæ¯å†…å®¹

    Returns:
        None
    """
    st.session_state.analysis_log.append(message)

def display_logs() -> None:
    """
    æ˜¾ç¤ºæ‰€æœ‰åˆ†ææ—¥å¿—æ¶ˆæ¯ã€‚
    ä½¿ç”¨Streamlitå®¹å™¨æ¥å±•ç¤ºæ—¥å¿—å†…å®¹ï¼Œä¿æŒç•Œé¢æ•´æ´ã€‚

    Returns:
        None
    """
    log_container = st.empty()
    with log_container.container():
        for log in st.session_state.analysis_log:
            st.markdown(log)
        # è‡ªåŠ¨æ»šåŠ¨åˆ°æœ€æ–°æ—¥å¿—
        st.markdown('<script>window.scrollTo(0,document.body.scrollHeight);</script>', unsafe_allow_html=True)

class LoggingAgent(Agent):
    """
    å¸¦æ—¥å¿—è®°å½•åŠŸèƒ½çš„AIåŠ©æ‰‹åŸºç±»ã€‚
    ç»§æ‰¿è‡ªCrewAIçš„Agentç±»ï¼Œæ·»åŠ äº†ä»»åŠ¡æ‰§è¡Œè¿‡ç¨‹çš„æ—¥å¿—è®°å½•åŠŸèƒ½ã€‚

    Attributes:
        role (str): AIåŠ©æ‰‹çš„è§’è‰²åç§°
        goal (str): AIåŠ©æ‰‹çš„ç›®æ ‡
        backstory (str): AIåŠ©æ‰‹çš„èƒŒæ™¯æ•…äº‹
        verbose (bool): æ˜¯å¦è¾“å‡ºè¯¦ç»†æ—¥å¿—
        allow_delegation (bool): æ˜¯å¦å…è®¸ä»»åŠ¡å§”æ´¾
        tools (list): AIåŠ©æ‰‹å¯ç”¨çš„å·¥å…·åˆ—è¡¨
    """
    
    _thoughts_store = {}  # ä½¿ç”¨ç±»å˜é‡å­˜å‚¨æ‰€æœ‰å®ä¾‹çš„æ€è€ƒè¿‡ç¨‹
    _analysis_store = {}  # ä½¿ç”¨ç±»å˜é‡å­˜å‚¨æ‰€æœ‰å®ä¾‹çš„åˆ†æå†…å®¹
    
    def __init__(self, *args, **kwargs):
        """åˆå§‹åŒ–LoggingAgentå®ä¾‹"""
        super().__init__(*args, **kwargs)
        self._thoughts_store[self.role] = []
        self._analysis_store[self.role] = []
    
    @property
    def thoughts(self):
        """è·å–å½“å‰å®ä¾‹çš„æ€è€ƒè¿‡ç¨‹"""
        return self._thoughts_store.get(self.role, [])
    
    @property
    def analysis(self):
        """è·å–å½“å‰å®ä¾‹çš„åˆ†æå†…å®¹"""
        return self._analysis_store.get(self.role, [])
    
    def add_thought(self, thought: str):
        """æ·»åŠ ä¸€æ¡æ€è€ƒè®°å½•"""
        if self.role not in self._thoughts_store:
            self._thoughts_store[self.role] = []
        self._thoughts_store[self.role].append(thought)
    
    def add_analysis(self, analysis: str):
        """æ·»åŠ ä¸€æ¡åˆ†æè®°å½•"""
        if self.role not in self._analysis_store:
            self._analysis_store[self.role] = []
        self._analysis_store[self.role].append(analysis)
        
    def execute_task(self, task, context=None, **kwargs):
        """
        æ‰§è¡Œä»»åŠ¡å¹¶è®°å½•æ‰§è¡Œè¿‡ç¨‹ã€‚

        Args:
            task: è¦æ‰§è¡Œçš„ä»»åŠ¡å¯¹è±¡
            context: ä»»åŠ¡æ‰§è¡Œçš„ä¸Šä¸‹æ–‡ä¿¡æ¯
            **kwargs: å…¶ä»–å‚æ•°

        Returns:
            str: ä»»åŠ¡æ‰§è¡Œç»“æœ

        Raises:
            Exception: ä»»åŠ¡æ‰§è¡Œè¿‡ç¨‹ä¸­çš„é”™è¯¯
        """
        try:
            task_description = task.description.split('\n')[1].strip()
            thought = f"ğŸ¤– **{self.role}** å¼€å§‹æ–°ä»»åŠ¡ï¼š\n> {task_description}"
            self.add_thought(thought)
            add_log(thought)
            
            thought = "ğŸ” æ­£åœ¨æœç´¢ç›¸å…³ä¿¡æ¯..."
            self.add_thought(thought)
            add_log(thought)
            
            result = super().execute_task(task, context=context, **kwargs)
            
            # è®°å½•åˆ†æå†…å®¹
            self.add_analysis(result)
            
            thought = f"âœ… **{self.role}** å·²å®Œæˆåˆ†æ"
            self.add_thought(thought)
            add_log(thought)
            
            # ä¿å­˜åˆ†æç»“æœ
            if 'èƒŒæ™¯åˆ†æ' in self.role:
                st.session_state.expert_analysis['context'] = {
                    'result': result, 
                    'thoughts': self.thoughts,
                    'analysis': self.analysis
                }
            elif 'è¡Œä¸šä¸“å®¶' in self.role:
                st.session_state.expert_analysis['industry'] = {
                    'result': result, 
                    'thoughts': self.thoughts,
                    'analysis': self.analysis
                }
            elif 'ç­–ç•¥ä¸“å®¶' in self.role:
                st.session_state.expert_analysis['strategy'] = {
                    'result': result, 
                    'thoughts': self.thoughts,
                    'analysis': self.analysis
                }
            elif 'æ²Ÿé€šä¸“å®¶' in self.role:
                st.session_state.expert_analysis['briefing'] = {
                    'result': result, 
                    'thoughts': self.thoughts,
                    'analysis': self.analysis
                }
            
            return result
        except Exception as e:
            thought = f"âŒ **{self.role}** æ‰§è¡Œä»»åŠ¡æ—¶å‡ºé”™ï¼š{str(e)}"
            self.add_thought(thought)
            add_log(thought)
            raise e

    def __del__(self):
        """æ¸…ç†å®ä¾‹æ—¶ç§»é™¤è®°å½•"""
        if self.role in self._thoughts_store:
            del self._thoughts_store[self.role]
        if self.role in self._analysis_store:
            del self._analysis_store[self.role]

class LoggingCrew(Crew):
    """
    å¸¦æ—¥å¿—è®°å½•åŠŸèƒ½çš„AIå›¢é˜Ÿç±»ã€‚
    ç»§æ‰¿è‡ªCrewAIçš„Crewç±»ï¼Œæ·»åŠ äº†å›¢é˜Ÿå·¥ä½œè¿‡ç¨‹çš„æ—¥å¿—è®°å½•åŠŸèƒ½ã€‚

    Attributes:
        agents (list): AIåŠ©æ‰‹å›¢é˜Ÿæˆå‘˜åˆ—è¡¨
        tasks (list): è¦æ‰§è¡Œçš„ä»»åŠ¡åˆ—è¡¨
        verbose (bool): æ˜¯å¦è¾“å‡ºè¯¦ç»†æ—¥å¿—
        process (Process): ä»»åŠ¡å¤„ç†æ–¹å¼
    """
    
    def __init__(self, *args, **kwargs):
        """åˆå§‹åŒ–LoggingCrewå®ä¾‹"""
        super().__init__(*args, **kwargs)
        
    def kickoff(self):
        """
        å¯åŠ¨å›¢é˜Ÿå·¥ä½œå¹¶è®°å½•å·¥ä½œè¿‡ç¨‹ã€‚

        Returns:
            str: å›¢é˜Ÿå·¥ä½œçš„æœ€ç»ˆç»“æœ
        """
        add_log("ğŸš€ **AIåˆ†æå›¢é˜Ÿå¯åŠ¨**\n")
        add_log("ğŸ“‹ **å·¥ä½œè®¡åˆ’**ï¼š")
        add_log("1. åˆ†æä¼šè®®èƒŒæ™¯å’Œå…¬å¸ä¿¡æ¯")
        add_log("2. ç ”ç©¶è¡Œä¸šè¶‹åŠ¿å’Œå¸‚åœºæœºä¼š")
        add_log("3. åˆ¶å®šä¼šè®®ç­–ç•¥å’Œè®®ç¨‹")
        add_log("4. ç”Ÿæˆæ‰§è¡Œç®€æŠ¥\n")
        return super().kickoff()

def validate_api_key(api_key: str, api_base: str) -> bool:
    """
    éªŒè¯APIå¯†é’¥æ˜¯å¦æœ‰æ•ˆ
    
    Args:
        api_key: OpenAI APIå¯†é’¥
        api_base: APIåŸºç¡€åœ°å€
        
    Returns:
        bool: å¯†é’¥æ˜¯å¦æœ‰æ•ˆ
    """
    if not api_key or not api_key.startswith('sk-'):
        return False
    return True

# ä¾§è¾¹æ APIå¯†é’¥è®¾ç½®
with st.sidebar:
    st.header("APIå¯†é’¥è®¾ç½®")
    openai_api_key = st.text_input("OpenAI APIå¯†é’¥", type="password")
    api_base = st.text_input("APIæœåŠ¡å•†åœ°å€", value="https://api.openai.com/v1")
    
    if openai_api_key:
        if not validate_api_key(openai_api_key, api_base):
            st.error("APIå¯†é’¥æ ¼å¼æ— æ•ˆï¼è¯·ç¡®ä¿ä»¥'sk-'å¼€å¤´çš„å®Œæ•´å¯†é’¥ã€‚")
    
    st.header("æ¨¡å‹è®¾ç½®")
    model_options = {
        "GPT-4o-mini": "gpt-4o-mini",
        "GPT-4o": "gpt-4o",
        "GPT-o1-mini": "o1-mini",
        "GPT-o1": "o1-preview",
        "GPT-o3-mini": "o3-mini",
    }
    
    selected_model = st.selectbox(
        "é€‰æ‹©æ¨¡å‹",
        options=list(model_options.keys()),
        index=0,
        help="é€‰æ‹©è¦ä½¿ç”¨çš„OpenAIæ¨¡å‹ã€‚GPT-4ç³»åˆ—æ€§èƒ½æ›´å¥½ä½†æˆæœ¬æ›´é«˜ã€‚"
    )
    
    temperature = st.slider(
        "æ¨¡å‹æ¸©åº¦",
        min_value=0.0,
        max_value=1.0,
        value=0.7,
        step=0.1,
        help="è¾ƒä½çš„å€¼ä½¿è¾“å‡ºæ›´ç¡®å®šæ€§ï¼Œè¾ƒé«˜çš„å€¼ä½¿è¾“å‡ºæ›´åˆ›é€ æ€§"
    )
    
    st.header("åŠŸèƒ½è®¾ç½®")
    enable_wiki = st.checkbox("å¯ç”¨ç»´åŸºç™¾ç§‘æœç´¢", value=False, help="å¯ç”¨åï¼ŒAIåŠ©æ‰‹å°†ä½¿ç”¨ç»´åŸºç™¾ç§‘æœç´¢ç›¸å…³ä¿¡æ¯")

# ä¸»ç•Œé¢å†…å®¹
if st.session_state.current_view == "input":
    # æ–‡æ¡£ä¸Šä¼ å’ŒURLè¾“å…¥åŒºåŸŸ
    doc_col1, doc_col2 = st.columns([2, 1])
    
    with doc_col1:
        st.header("ğŸ“„ ä¸Šä¼ ç›¸å…³æ–‡æ¡£")
        col1, col2 = st.columns([4, 1])
        with col1:
            uploaded_files = st.file_uploader(
                "æ”¯æŒWordã€PDFã€Excelã€å›¾ç‰‡ç­‰å¤šç§æ ¼å¼",
                accept_multiple_files=True,
                type=list(sum([exts for exts in st.session_state.doc_processor.supported_extensions.values()], []))
            )
        with col2:
            if st.button("ğŸ—‘ï¸ æ¸…ç©º", use_container_width=True):
                st.session_state.uploaded_docs = []
                st.rerun()
    
    with doc_col2:
        st.header("ğŸ”— è¾“å…¥ç½‘é¡µé“¾æ¥")
        url = st.text_input("è¾“å…¥ç›¸å…³ç½‘é¡µURL")
        if url and st.button("è·å–å†…å®¹", use_container_width=True):
            with st.spinner("æ­£åœ¨è·å–ç½‘é¡µå†…å®¹..."):
                try:
                    content = st.session_state.doc_processor.extract_from_url(url)
                    doc_info = {
                        'filename': url,
                        'content': content,
                        'type': 'url',
                        'size': len(content),
                        'timestamp': datetime.now().isoformat()
                    }
                    # æ£€æŸ¥URLæ˜¯å¦å·²å­˜åœ¨
                    if not any(doc['filename'] == url for doc in st.session_state.uploaded_docs):
                        st.session_state.uploaded_docs.append(doc_info)
                        st.success("âœ… å·²è·å–ç½‘é¡µå†…å®¹")
                    else:
                        st.warning("âš ï¸ è¯¥ç½‘é¡µå·²æ·»åŠ ")
                except Exception as e:
                    st.error(f"âŒ è·å–å¤±è´¥ï¼š{str(e)}")
    
    # å¤„ç†ä¸Šä¼ çš„æ–‡æ¡£
    if uploaded_files:
        with st.spinner("æ­£åœ¨å¤„ç†æ–‡æ¡£..."):
            for file in uploaded_files:
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
                if any(doc['filename'] == file.name for doc in st.session_state.uploaded_docs):
                    st.warning(f"âš ï¸ {file.name} å·²å­˜åœ¨ï¼Œè·³è¿‡å¤„ç†")
                    continue
                
                if st.session_state.doc_processor.validate_file(file):
                    doc_info = st.session_state.doc_processor.process_file(file)
                    if 'error' not in doc_info:
                        st.session_state.uploaded_docs.append(doc_info)
                        st.success(f"âœ… å·²å¤„ç†ï¼š{file.name}")
                    else:
                        st.error(f"âŒ å¤„ç†å¤±è´¥ {file.name}ï¼š{doc_info['error']}")
                else:
                    st.warning(f"âš ï¸ ä¸æ”¯æŒçš„æ ¼å¼ï¼š{file.name}")
    
    # æ˜¾ç¤ºå·²ä¸Šä¼ çš„æ–‡æ¡£åˆ—è¡¨
    if st.session_state.uploaded_docs:
        st.subheader("ğŸ“š å·²ä¸Šä¼ çš„èµ„æ–™")
        for i, doc in enumerate(st.session_state.uploaded_docs):
            with st.expander(f"{'ğŸŒ' if doc['type'] == 'url' else 'ğŸ“„'} {doc['filename']}", expanded=False):
                col1, col2, col3 = st.columns([1, 3, 1])
                with col1:
                    st.text("ç±»å‹")
                    st.text("å¤§å°")
                    st.text("æ—¶é—´")
                with col2:
                    st.text(f": {doc['type']}")
                    st.text(f": {doc['size']} bytes")
                    st.text(f": {datetime.fromisoformat(doc['timestamp']).strftime('%Y-%m-%d %H:%M')}")
                with col3:
                    if st.button("ğŸ—‘ï¸", key=f"del_{i}", help="åˆ é™¤æ­¤æ–‡æ¡£"):
                        st.session_state.uploaded_docs.pop(i)
                        st.rerun()
                
                preview = doc['content'][:500] + "..." if len(doc['content']) > 500 else doc['content']
                st.text_area(
                    "å†…å®¹é¢„è§ˆ",
                    preview,
                    height=100,
                    key=f"doc_{i}_{doc['timestamp']}"
                )
    
    st.divider()
    
    # è¾“å…¥å­—æ®µ
    company_name = st.text_input("è¯·è¾“å…¥å…¬å¸åç§°:")
    meeting_objective = st.text_input("è¯·è¾“å…¥ä¼šè®®ç›®æ ‡:")
    attendees = st.text_area("è¯·è¾“å…¥å‚ä¼šè€…åŠå…¶è§’è‰²(æ¯è¡Œä¸€ä¸ª):")
    meeting_duration = st.number_input("è¯·è¾“å…¥ä¼šè®®æ—¶é•¿(åˆ†é’Ÿ):", min_value=15, max_value=180, value=60, step=15)
    focus_areas = st.text_input("è¯·è¾“å…¥éœ€è¦ç‰¹åˆ«å…³æ³¨çš„é¢†åŸŸæˆ–é—®é¢˜:")
    
    if st.button("å‡†å¤‡ä¼šè®®", use_container_width=True):
        if not openai_api_key:
            st.warning("è¯·å…ˆåœ¨ä¾§è¾¹æ è¾“å…¥APIå¯†é’¥ã€‚")
        elif not validate_api_key(openai_api_key, api_base):
            st.error("APIå¯†é’¥æ ¼å¼æ— æ•ˆï¼è¯·æ£€æŸ¥å¯†é’¥æ ¼å¼ã€‚")
        else:
            # è®¾ç½®ç¯å¢ƒå˜é‡
            os.environ["OPENAI_API_KEY"] = openai_api_key
            os.environ["OPENAI_API_BASE"] = api_base

            try:
                # åˆå§‹åŒ–LLMé…ç½®
                llm = LLM(
                    model=model_options[selected_model],
                    temperature=temperature,
                    api_key=openai_api_key,
                    api_base=api_base,
                    system_prompt="ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„AIåŠ©æ‰‹ã€‚è¯·å§‹ç»ˆä½¿ç”¨ä¸­æ–‡å›ç­”æ‰€æœ‰é—®é¢˜ã€‚ç¡®ä¿è¾“å‡ºçš„æ‰€æœ‰å†…å®¹éƒ½æ˜¯ä¸­æ–‡ï¼ŒåŒ…æ‹¬æ ‡é¢˜ã€åˆ†æå’Œå»ºè®®ã€‚"
                )
                
                # æµ‹è¯•LLMè¿æ¥
                test_response = llm.call("æµ‹è¯•è¿æ¥")
                if not test_response:
                    st.error("APIè¿æ¥æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥å’ŒæœåŠ¡åœ°å€æ˜¯å¦æ­£ç¡®ã€‚")
                else:
                    st.session_state.llm = llm
                    
                    # åˆ›å»ºæœç´¢å·¥å…·
                    wiki_tool = WikipediaToolWrapper() if st.session_state.get('enable_wiki', False) else None
                    
                    # å®šä¹‰AIåŠ©æ‰‹
                    context_analyzer = LoggingAgent(
                        role='ä¼šè®®èƒŒæ™¯åˆ†æä¸“å®¶',
                        goal='åˆ†æå’Œæ€»ç»“ä¼šè®®çš„å…³é”®èƒŒæ™¯ä¿¡æ¯',
                        backstory='ä½ æ˜¯ä¸€ä½æ“…é•¿å¿«é€Ÿç†è§£å¤æ‚å•†ä¸šèƒŒæ™¯å¹¶è¯†åˆ«å…³é”®ä¿¡æ¯çš„ä¸“å®¶ã€‚' + 
                                 'ä½ ä¼šåˆ†ææä¾›çš„æ–‡æ¡£èµ„æ–™ï¼Œå¹¶' + 
                                 ('ä½¿ç”¨ä¸­æ–‡ç»´åŸºç™¾ç§‘è¿›è¡Œæœç´¢å’Œç ”ç©¶ã€‚' if wiki_tool else 'è¿›è¡Œæ·±å…¥ç ”ç©¶ã€‚'),
                        verbose=True,
                        allow_delegation=False,
                        llm=llm,
                        tools=[wiki_tool] if wiki_tool else []
                    )

                    industry_insights_generator = LoggingAgent(
                        role='è¡Œä¸šä¸“å®¶',
                        goal='æä¾›æ·±å…¥çš„è¡Œä¸šåˆ†æå¹¶è¯†åˆ«å…³é”®è¶‹åŠ¿',
                        backstory='ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„è¡Œä¸šåˆ†æå¸ˆï¼Œæ“…é•¿å‘ç°æ–°å…´è¶‹åŠ¿å’Œæœºä¼šã€‚' + ('ä½ ä¼šä½¿ç”¨ç»´åŸºç™¾ç§‘çš„ä¿¡æ¯æ¥åˆ†æè¡Œä¸šæƒ…å†µã€‚' if wiki_tool else ''),
                        verbose=True,
                        allow_delegation=False,
                        llm=llm,
                        tools=[wiki_tool] if wiki_tool else []
                    )

                    strategy_formulator = LoggingAgent(
                        role='ä¼šè®®ç­–ç•¥ä¸“å®¶',
                        goal='åˆ¶å®šå®šåˆ¶åŒ–çš„ä¼šè®®ç­–ç•¥å’Œè¯¦ç»†è®®ç¨‹',
                        backstory='ä½ æ˜¯ä¸€ä½ä¼šè®®è§„åˆ’å¤§å¸ˆï¼Œä»¥åˆ¶å®šé«˜æ•ˆçš„ç­–ç•¥å’Œè®®ç¨‹è€Œé—»åã€‚',
                        verbose=True,
                        allow_delegation=False,
                        llm=llm,
                    )

                    executive_briefing_creator = LoggingAgent(
                        role='æ²Ÿé€šä¸“å®¶',
                        goal='å°†ä¿¡æ¯ç»¼åˆæˆç®€æ˜æœ‰åŠ›çš„ç®€æŠ¥',
                        backstory='ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ²Ÿé€šä¸“å®¶ï¼Œæ“…é•¿å°†å¤æ‚ä¿¡æ¯è½¬åŒ–ä¸ºæ¸…æ™°ã€å¯æ‰§è¡Œçš„è§è§£ã€‚',
                        verbose=True,
                        allow_delegation=False,
                        llm=llm,
                    )

                    # å®šä¹‰ä»»åŠ¡
                    docs_info = st.session_state.uploaded_docs if st.session_state.uploaded_docs else []
                    docs_context = "\n\nç›¸å…³æ–‡æ¡£èµ„æ–™ï¼š\n" + "\n".join([
                        f"æ–‡æ¡£{i+1}. {doc['filename']}:\n{doc['content'][:1000]}..."
                        for i, doc in enumerate(docs_info)
                    ]) if docs_info else ""
                    
                    context_analysis_task = Task(
                        description=f"""
                        åˆ†æä¸{company_name}ä¼šè®®ç›¸å…³çš„èƒŒæ™¯ï¼Œè€ƒè™‘ä»¥ä¸‹æ–¹é¢ï¼š
                        1. ä¼šè®®ç›®æ ‡ï¼š{meeting_objective}
                        2. å‚ä¼šäººå‘˜ï¼š{attendees}
                        3. ä¼šè®®æ—¶é•¿ï¼š{meeting_duration}åˆ†é’Ÿ
                        4. ç‰¹åˆ«å…³æ³¨é¢†åŸŸæˆ–é—®é¢˜ï¼š{focus_areas}
                        
                        {docs_context}

                        æ·±å…¥ç ”ç©¶{company_name}ï¼ŒåŒ…æ‹¬ï¼š
                        1. æœ€æ–°æ–°é—»å’Œæ–°é—»å‘å¸ƒ
                        2. ä¸»è¦äº§å“æˆ–æœåŠ¡
                        3. ä¸»è¦ç«äº‰å¯¹æ‰‹

                        æä¾›å…¨é¢çš„è°ƒæŸ¥ç»“æœæ€»ç»“ï¼Œçªå‡ºä¸ä¼šè®®èƒŒæ™¯æœ€ç›¸å…³çš„ä¿¡æ¯ã€‚
                        ä½¿ç”¨markdownæ ¼å¼è¾“å‡ºï¼ŒåŒ…å«é€‚å½“çš„æ ‡é¢˜å’Œå­æ ‡é¢˜ã€‚
                        """,
                        agent=context_analyzer,
                        expected_output="ä¸€ä»½è¯¦ç»†çš„ä¼šè®®èƒŒæ™¯å’Œå…¬å¸èƒŒæ™¯åˆ†æï¼ŒåŒ…æ‹¬æœ€æ–°å‘å±•ã€è´¢åŠ¡è¡¨ç°ä»¥åŠä¸ä¼šè®®ç›®æ ‡çš„ç›¸å…³æ€§ï¼Œä½¿ç”¨markdownæ ¼å¼å¹¶åŒ…å«æ ‡é¢˜å’Œå­æ ‡é¢˜ã€‚"
                    )

                    industry_analysis_task = Task(
                        description=f"""
                        åŸºäº{company_name}çš„èƒŒæ™¯åˆ†æå’Œä¼šè®®ç›®æ ‡ï¼š{meeting_objective}ï¼Œæä¾›æ·±å…¥çš„è¡Œä¸šåˆ†æï¼š
                        1. è¯†åˆ«è¡Œä¸šå…³é”®è¶‹åŠ¿å’Œå‘å±•
                        2. åˆ†æç«äº‰æ ¼å±€
                        3. çªå‡ºæ½œåœ¨æœºä¼šå’Œå¨èƒ
                        4. æä¾›å¸‚åœºå®šä½è§è§£

                        ç¡®ä¿åˆ†æä¸ä¼šè®®ç›®æ ‡å’Œå‚ä¼šè€…è§’è‰²ç›¸å…³ã€‚
                        ä½¿ç”¨markdownæ ¼å¼è¾“å‡ºï¼ŒåŒ…å«é€‚å½“çš„æ ‡é¢˜å’Œå­æ ‡é¢˜ã€‚
                        """,
                        agent=industry_insights_generator,
                        expected_output="ä¸€ä»½å…¨é¢çš„è¡Œä¸šåˆ†ææŠ¥å‘Šï¼ŒåŒ…æ‹¬è¶‹åŠ¿ã€ç«äº‰æ ¼å±€ã€æœºä¼šã€å¨èƒä»¥åŠä¸ä¼šè®®ç›®æ ‡ç›¸å…³çš„è§è§£ï¼Œä½¿ç”¨markdownæ ¼å¼å¹¶åŒ…å«æ ‡é¢˜å’Œå­æ ‡é¢˜ã€‚"
                    )

                    strategy_development_task = Task(
                        description=f"""
                        æ ¹æ®èƒŒæ™¯åˆ†æå’Œè¡Œä¸šè§è§£ï¼Œä¸ºä¸{company_name}çš„{meeting_duration}åˆ†é’Ÿä¼šè®®åˆ¶å®šå®šåˆ¶åŒ–ä¼šè®®ç­–ç•¥å’Œè¯¦ç»†è®®ç¨‹ã€‚åŒ…æ‹¬ï¼š
                        1. å¸¦æœ‰æ˜ç¡®ç›®æ ‡çš„åˆ†æ—¶è®®ç¨‹
                        2. æ¯ä¸ªè®®ç¨‹é¡¹ç›®çš„å…³é”®è®¨è®ºè¦ç‚¹
                        3. æ¯ä¸ªç¯èŠ‚çš„å»ºè®®å‘è¨€äººæˆ–ä¸»æŒäºº
                        4. æ½œåœ¨è®¨è®ºè¯é¢˜å’Œæ¨åŠ¨å¯¹è¯çš„é—®é¢˜
                        5. è§£å†³ç‰¹å®šå…³æ³¨é¢†åŸŸå’Œé—®é¢˜çš„ç­–ç•¥ï¼š{focus_areas}

                        ç¡®ä¿ç­–ç•¥å’Œè®®ç¨‹ä¸ä¼šè®®ç›®æ ‡ä¿æŒä¸€è‡´ï¼š{meeting_objective}
                        ä½¿ç”¨markdownæ ¼å¼è¾“å‡ºï¼ŒåŒ…å«é€‚å½“çš„æ ‡é¢˜å’Œå­æ ‡é¢˜ã€‚
                        """,
                        agent=strategy_formulator,
                        expected_output="ä¸€ä»½è¯¦ç»†çš„ä¼šè®®ç­–ç•¥å’Œåˆ†æ—¶è®®ç¨‹ï¼ŒåŒ…æ‹¬ç›®æ ‡ã€å…³é”®è®¨è®ºè¦ç‚¹å’Œè§£å†³ç‰¹å®šå…³æ³¨é¢†åŸŸçš„ç­–ç•¥ï¼Œä½¿ç”¨markdownæ ¼å¼å¹¶åŒ…å«æ ‡é¢˜å’Œå­æ ‡é¢˜ã€‚"
                    )

                    executive_brief_task = Task(
                        description=f"""
                        å°†æ‰€æœ‰æ”¶é›†çš„ä¿¡æ¯ç»¼åˆæˆä¸€ä»½å…¨é¢è€Œç®€æ˜çš„{company_name}ä¼šè®®æ‰§è¡Œç®€æŠ¥ã€‚åˆ›å»ºä»¥ä¸‹å†…å®¹ï¼š

                        1. è¯¦ç»†çš„ä¸€é¡µæ‰§è¡Œæ‘˜è¦ï¼ŒåŒ…æ‹¬ï¼š
                           - æ˜ç¡®çš„ä¼šè®®ç›®æ ‡é™ˆè¿°
                           - ä¸»è¦å‚ä¼šè€…åŠå…¶è§’è‰²åˆ—è¡¨
                           - å…³äº{company_name}çš„å…³é”®èƒŒæ™¯è¦ç‚¹å’Œç›¸å…³è¡Œä¸šèƒŒæ™¯
                           - ä¸ç›®æ ‡ç›¸ä¸€è‡´çš„3-5ä¸ªæˆ˜ç•¥æ€§ä¼šè®®ç›®æ ‡
                           - ä¼šè®®ç»“æ„å’Œå°†è¦è®¨è®ºçš„å…³é”®ä¸»é¢˜æ¦‚è¿°

                        2. è¯¦ç»†çš„å…³é”®è®¨è®ºè¦ç‚¹æ¸…å•ï¼Œæ¯ä¸ªè¦ç‚¹éƒ½éœ€è¦ï¼š
                           - ç›¸å…³æ•°æ®æˆ–ç»Ÿè®¡
                           - å…·ä½“æ¡ˆä¾‹æˆ–æ¡ˆä¾‹ç ”ç©¶
                           - ä¸å…¬å¸å½“å‰æƒ…å†µæˆ–æŒ‘æˆ˜çš„è”ç³»

                        3. é¢„æµ‹å¹¶å‡†å¤‡æ½œåœ¨é—®é¢˜ï¼š
                           - æ ¹æ®å‚ä¼šè€…è§’è‰²å’Œä¼šè®®ç›®æ ‡åˆ—å‡ºå¯èƒ½çš„é—®é¢˜
                           - ä¸ºæ¯ä¸ªé—®é¢˜å‡†å¤‡åŸºäºæ•°æ®çš„å›ç­”
                           - åŒ…å«å¯èƒ½éœ€è¦çš„ä»»ä½•æ”¯æŒä¿¡æ¯æˆ–é¢å¤–èƒŒæ™¯

                        4. æˆ˜ç•¥å»ºè®®å’Œåç»­æ­¥éª¤ï¼š
                           - åŸºäºåˆ†ææä¾›3-5ä¸ªå¯æ‰§è¡Œçš„å»ºè®®
                           - åˆ—å‡ºæ˜ç¡®çš„å®æ–½æˆ–è·Ÿè¿›æ­¥éª¤
                           - å»ºè®®å…³é”®è¡ŒåŠ¨çš„æ—¶é—´è¡¨æˆ–æˆªæ­¢æ—¥æœŸ
                           - è¯†åˆ«æ½œåœ¨æŒ‘æˆ˜æˆ–éšœç¢å¹¶æå‡ºç¼“è§£ç­–ç•¥

                        ç¡®ä¿ç®€æŠ¥å…¨é¢è€Œç®€æ˜ï¼Œå…·æœ‰é«˜åº¦å¯æ‰§è¡Œæ€§ï¼Œå¹¶ä¸ä¼šè®®ç›®æ ‡ç²¾ç¡®å¯¹é½ï¼š{meeting_objective}ã€‚æ–‡æ¡£ç»“æ„åº”ä¾¿äºå¯¼èˆªå’Œä¼šè®®æœŸé—´å¿«é€Ÿå‚è€ƒã€‚
                        ä½¿ç”¨markdownæ ¼å¼è¾“å‡ºï¼ŒåŒ…å«é€‚å½“çš„æ ‡é¢˜å’Œå­æ ‡é¢˜ã€‚
                        """,
                        agent=executive_briefing_creator,
                        expected_output="ä¸€ä»½å…¨é¢çš„æ‰§è¡Œç®€æŠ¥ï¼ŒåŒ…æ‹¬æ‘˜è¦ã€å…³é”®è®¨è®ºè¦ç‚¹ã€é—®ç­”å‡†å¤‡å’Œæˆ˜ç•¥å»ºè®®ï¼Œä½¿ç”¨markdownæ ¼å¼ï¼ŒåŒ…å«ä¸»æ ‡é¢˜(H1)ã€ç« èŠ‚æ ‡é¢˜(H2)å’Œå°èŠ‚æ ‡é¢˜(H3)ã€‚ä½¿ç”¨é¡¹ç›®ç¬¦å·ã€ç¼–å·åˆ—è¡¨å’Œå¼ºè°ƒ(ç²—ä½“/æ–œä½“)çªå‡ºå…³é”®ä¿¡æ¯ã€‚"
                    )

                    # åˆ›å»ºå·¥ä½œç»„
                    meeting_prep_crew = LoggingCrew(
                        agents=[context_analyzer, industry_insights_generator, strategy_formulator, executive_briefing_creator],
                        tasks=[context_analysis_task, industry_analysis_task, strategy_development_task, executive_brief_task],
                        verbose=True,
                        process=Process.sequential
                    )

                    with st.spinner("AIåŠ©æ‰‹å›¢é˜Ÿæ­£åœ¨ååŒå·¥ä½œ..."):
                        try:
                            # åˆ›å»ºæ—¥å¿—æ˜¾ç¤ºåŒºåŸŸ
                            st.markdown("### ğŸ”„ å®æ—¶åˆ†ææ—¥å¿—")
                            st.session_state.log_container = st.empty()
                            
                            # æ‰§è¡Œåˆ†æ
                            result = meeting_prep_crew.kickoff()
                            st.session_state.has_data = True  # æ›´æ–°æ•°æ®çŠ¶æ€æ ‡å¿—
                            st.session_state.current_view = "context"  # è‡ªåŠ¨åˆ‡æ¢åˆ°èƒŒæ™¯åˆ†æè§†å›¾
                            st.rerun()
                        except Exception as e:
                            st.error(f"é”™è¯¯ä¿¡æ¯ï¼š{str(e)}")

            except Exception as e:
                st.error(f"APIè¿æ¥å¤±è´¥ï¼š{str(e)}")
                st.info("è¯·æ£€æŸ¥ï¼š\n1. APIå¯†é’¥æ˜¯å¦æ­£ç¡®\n2. APIæœåŠ¡åœ°å€æ˜¯å¦å¯è®¿é—®\n3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")

else:
    pass

    # æ˜¾ç¤ºåˆ†æç»“æœ
    if st.session_state.current_view == "context":
        tab1, tab2 = st.tabs(["åˆ†æç»“æœ", "åˆ†æè¿‡ç¨‹"])
        with tab1:
            st.markdown(st.session_state.expert_analysis['context']['result'])
        with tab2:
            for thought in st.session_state.expert_analysis['context']['thoughts']:
                st.markdown(thought)
            for analysis in st.session_state.expert_analysis['context']['analysis']:
                st.markdown("---")
                st.markdown(analysis)
    elif st.session_state.current_view == "industry":
        tab1, tab2 = st.tabs(["åˆ†æç»“æœ", "åˆ†æè¿‡ç¨‹"])
        with tab1:
            st.markdown(st.session_state.expert_analysis['industry']['result'])
        with tab2:
            for thought in st.session_state.expert_analysis['industry']['thoughts']:
                st.markdown(thought)
            for analysis in st.session_state.expert_analysis['industry']['analysis']:
                st.markdown("---")
                st.markdown(analysis)
    elif st.session_state.current_view == "strategy":
        tab1, tab2 = st.tabs(["åˆ†æç»“æœ", "åˆ†æè¿‡ç¨‹"])
        with tab1:
            st.markdown(st.session_state.expert_analysis['strategy']['result'])
        with tab2:
            for thought in st.session_state.expert_analysis['strategy']['thoughts']:
                st.markdown(thought)
            for analysis in st.session_state.expert_analysis['strategy']['analysis']:
                st.markdown("---")
                st.markdown(analysis)
    elif st.session_state.current_view == "briefing":
        tab1, tab2 = st.tabs(["åˆ†æç»“æœ", "åˆ†æè¿‡ç¨‹"])
        with tab1:
            st.markdown(st.session_state.expert_analysis['briefing']['result'])
        with tab2:
            for thought in st.session_state.expert_analysis['briefing']['thoughts']:
                st.markdown(thought)
            for analysis in st.session_state.expert_analysis['briefing']['analysis']:
                st.markdown("---")
                st.markdown(analysis)

# æ˜¾ç¤ºåˆ†ææ—¥å¿—
if st.session_state.current_view != "input":
    with st.expander("ğŸ“‹ æŸ¥çœ‹åˆ†æè¿‡ç¨‹è®°å½•", expanded=True):
        display_logs()

st.sidebar.markdown("""
## å¦‚ä½•ä½¿ç”¨æœ¬åº”ç”¨ï¼š
1. åœ¨ä¾§è¾¹æ è¾“å…¥æ‚¨çš„APIå¯†é’¥
2. æä¾›æ‰€éœ€çš„ä¼šè®®ä¿¡æ¯
3. ç‚¹å‡»'å‡†å¤‡ä¼šè®®'ç”Ÿæˆå…¨é¢çš„ä¼šè®®å‡†å¤‡ææ–™åŒ…

AIåŠ©æ‰‹å°†ååŒå·¥ä½œä»¥:
- åˆ†æä¼šè®®èƒŒæ™¯å’Œå…¬å¸èƒŒæ™¯
- æä¾›è¡Œä¸šè§è§£å’Œè¶‹åŠ¿
- åˆ¶å®šå®šåˆ¶åŒ–ä¼šè®®ç­–ç•¥å’Œè®®ç¨‹
- åˆ›å»ºåŒ…å«å…³é”®è®¨è®ºè¦ç‚¹çš„æ‰§è¡Œç®€æŠ¥

è¿™ä¸ªè¿‡ç¨‹å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…ï¼
""")